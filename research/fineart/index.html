
<html>
	
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
	<title>RIDI | Projects: An Exemplar-Based Method for Visual Editing and Retouching of Fine Art Reproduction</title>
	<meta name="description" content="An Exemplar-Based Method for Automatic Visual Editing and Retouching of Fine Art Reproduction">
	<meta name="keyword" content="Computer Vision, RIDI, Information-Driven Imaging Lab, Center for Imaging Science, Rochester Institute of Technology, Projects, An Exemplar-Based  
Method for Automatic Visual Editing and Retouching of Fine Art Reproduction">
	<link rel="stylesheet" href="../projects.css" type="text/css" />
</head>

<body bgcolor=#ffffff>
	<table width="982" height="100%"  border="0" cellpadding=0 cellspacing=0 align="center">
		<tr>
			<td width="59" rowspan="3" align="left" valign="baseline" background="../bkgnd/left_side.gif">&nbsp;</td>
			<td width="864" height="42" align="left" valign="baseline" background="../bkgnd/top_thin.gif"></td>
			<td width="59" rowspan="3" align="left" valign="baseline" background="../bkgnd/right_side.gif">&nbsp;</td>
		</tr>
		<tr>
			<td height="100%" align="left" valign="baseline" bgcolor="#ffffff">
			<div align="center"><table width="709"  border="0" cellspacing="30" cellpadding="0">
		
				<tr>
					<td><div align="center"><font size="+2">An Exemplar-Based Method for Automatic Visual Editing and Retouching of Fine Art Reproduction</font></div></td>
				</tr><tr>
						<td><center><img src="./img/exemplar.jpg" width="700"></center></td></tr><tr><td><p>The advance in camera and imaging technologies has made digital archiving and conservation of artworks possible in museums. Visual editing and retouching are usually made by experts in museums to match the reproduction with the original more closely. While effective, visual editing and retouching is time-consuming and labor-intensive. We addressed this problem by learning from the adjustments made by observers, and automatically making visual editing and retouching on incoming paintings. The evaluation results suggest that the image adjusted by our model is significantly better than the average of the images adjusted by observers.</p></td></tr>
				<tr>
					<td><h3 id="Publications">Publications</h3>
						<blockquote>
				<p>Jun Jiang and Jinwei Gu. <i><a href='cic13.pdf'>An Exemplar-Based Method for Automatic Visual Editing and Retouching of Fine Art Reproduction</a></i>. Color and Imaging Conference (CIC) 2013.<br>
						</blockquote>
					</td>
				</tr>
				
				<tr>
					<td align="left">
						<h3 id="Images">Images</h3>
				
						<table border="0" cellpadding="0" cellspacing="6">
				
						<tr>
							<td align="left" valign="middle" width="171"><a href="img/labSetup.jpg"><img class="imgthumb" src="img/thumb_labSetup.jpg" border="1" /></a></td>
							<td align="left" valign="middle" width="10">&nbsp;</td>
							<td align="left" valign="middle" width="512">
								<strong>Experimental setup:</strong>
								<p class="mediadescription">(a) Painting acquisition. Canon 60D is mounted perpendicular to the painting on the stage. Two diffuse studio lightings are put on both sides at 45 degree from the stage. ColorChecker is used to correct image white balance after capturing. (b) The setup for visual editing and retouching. Observers were asked to adjust the image on the display to match with the original in the light booth. (c) The setup for the paired-comparison experiment. Observers were asked to choose the image on the display that matches with the original in the light booth more closely.</p>
							</td>
						</tr>
					
						<tr>
							<td align="left" valign="middle" width="171"><a href="img/adjustmentWorkflow.jpg"><img class="imgthumb" src="img/
thumb_adjustmentWorkflow.jpg" border="1" /></a></td>
							<td align="left" valign="middle" width="10">&nbsp;</td>
							<td align="left" valign="middle" width="512">
								<strong>The pipeline to make visual editing and retouching of the captured images:</strong>
								<p class="mediadescription">The components in the dashed-line rectangle in (a) correspond to the adjustments by observers. User interfaces: (b) hue, (c) global, (d) local, and (e) sharpness. </p>
							</td>
						</tr>
					
						<tr>
							<td align="left" valign="middle" width="171"><a href="img/localAdjWorkflow.jpg"><img class="imgthumb" src="img/thumb_localAdjWorkflow.jpg" border="1" /></a></td>
							<td align="left" valign="middle" width="10">&nbsp;</td>
							<td align="left" valign="middle" width="512">
								<strong>The workflow for local adjustments:</strong>
								<p class="mediadescription"> The new painting, Daisy is matched to Boats (Best match). Local adjustments are made by comparing the dominant color and their neighboring colors of Daisy with those of Boats. In the Selected colors by observers, below and above the diagonal within each patch is the color before and after local adjustments.</p>
							</td>
						</tr>
					
						<tr>
							<td align="left" valign="middle" width="171"><a href="img/dominantColorDistribution.jpg"><img class="imgthumb" src="img/thumb_dominantColorDistribution.
jpg" border="1" /></a></td>
							<td align="left" valign="middle" width="10">&nbsp;</td>
							<td align="left" valign="middle" width="512">
								<strong>The dominant colors extracted from the painting by Kmeans:</strong>
								<p class="mediadescription">Dominant colors in the 
painting of Daisy are learnt by Kmeans in (a), and their respective areas in the painting 
from (b) to (f). The five 
dominant colors are overlaid on the painting 
in (g), and it can be found most part of the painting is covered by 
the learnt dominant 
colors indicating the representation of dominant colors.</p>
							</td>
						</tr>
					
						<tr>
							<td align="left" valign="middle" width="171"><a href="img/evaluateModelPerformanceCI.jpg"><img class="imgthumb" src="img/
thumb_evaluateModelPerformanceCI.jpg" border="1" /></a></td>
							<td align="left" valign="middle" width="10">&nbsp;</td>
							<td align="left" valign="middle" width="512">
								<strong>The paired-comparison 
results for the five paintings:</strong>
								<p class="mediadescription">The blue dots are images adjusted by observers, and the red diamonds are the images predicted by our model. The greater the zscore, the more faithful the reproduction is to the original. Overall our model is ranked higher than the average of the images adjusted by observers. The paintings on the y-axis are the last five images in Fig.3 in the paper. Red bars are the 95% confidence intervals.</p>
							</td>
						</tr>
					
						<tr>
							<td align="left" valign="middle" width="171"><a href="img/firelightMDS.jpg"><img class="imgthumb" src="img/thumb_firelightMDS.jpg" border="1" /></a></td>
							<td align="left" valign="middle" width="10">&nbsp;</td>
							<td align="left" valign="middle" width="512">
								<strong>The adjustment results of Firelight at each step:</strong>
								<p class="mediadescription">(a) The original, (b) after global adjustments, (c) after local adjustments, and (d) after sharpness adjustment. Multidimensional scaling (MDS) is used to understand the contribution of each step based on color difference. The blue dots are the reproductions adjusted by observers, and the red dots are adjustments by our model at each step. Most of the changes in Firelight can be explained by the global adjustments.</p>
							</td>
						</tr>
					
						</table>
					</td>
				</tr>
				
				<tr>
					<td align="left"><h3 id="Slides">Slides</h3>
						<blockquote>
				<p><a href="./CIC_2013.pptx">CIC 2013 Presentation</a></p>

						</blockquote>
					</td>
				</tr>
				
				<tr>
					<td align="left">
						<h3 id="Related Project">Related Project</h3>
						<blockquote>
				<p><a href="http://research.microsoft.com/en-us/um/people/sbkang/projects/personalizedenhancement/

">Sing Bing Kang, Ashish Kapoor, and Dani Lischinski. Personalization of image enhancement. In CVPR, 2010.</a></p>

						</blockquote>
					</td>
				</tr>
		</table>

	</body>
</html>
